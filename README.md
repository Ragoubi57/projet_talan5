# ğŸ¦ Verifiable Banking Analytics

A regulated, auditable banking analytics demo system. Users ask analytics questions in natural language and receive charts, explanations, and cryptographically verifiable **Evidence Packs** for audit compliance.

## Architecture

```
NL Query â†’ Metadata Search â†’ DSL Plan â†’ Policy Eval (OPA) â†’ SQL Compile â†’ Execute (DuckDB) â†’ Evidence Pack
```

| Component | Technology |
|-----------|-----------|
| Analytics Engine | DuckDB |
| Transformations | dbt-core (staging â†’ gold models) |
| Quality Gates | Great Expectations-style checks |
| Policy Engine | OPA (Rego) with local fallback |
| Agent Orchestration | LangGraph-style state machine |
| SQL Validation | Regex-based validator + SHA256 hashing |
| Lineage | OpenLineage â†’ Marquez |
| UI | Streamlit + Altair charts |
| LLM | Ollama (mock LLM fallback included) |

## Quick Start

### Option 1: Docker Compose (recommended)

```bash
docker compose up --build
```

Open http://localhost:8501 for the Streamlit UI.

### Option 2: Local Development

```bash
pip install -r requirements.txt
make demo
```

Or step by step:

```bash
SMALL_MODE=1 python scripts/generate_synth_data.py
python scripts/seed_duckdb.py
python great_expectations/run_checks.py
python scripts/promote.py
streamlit run app/streamlit_app.py
```

## Data Products

| Data Product | Description | Rows (Small Mode) |
|-------------|-------------|-------------------|
| `dp_complaints` | Consumer complaints (CFPB-style) | 50,000 |
| `dp_call_reports` | Quarterly bank financials (FDIC-style) | 720 |

### Synthetic Data Generation

```bash
SMALL_MODE=1 python scripts/generate_synth_data.py   # 50K complaints
python scripts/generate_synth_data.py                  # 1M complaints (default)
```

## Roles & Access Control

| Role | LOW Data | MED Data | HIGH Data (Narratives) | Export |
|------|----------|----------|----------------------|--------|
| `branch_manager` | âœ… Allow | âŒ Deny | âŒ Deny | âŒ |
| `risk_officer` | âœ… Allow | âœ… Allow | âŒ Deny | âœ… |
| `compliance_officer` | âœ… Allow | âœ… Allow | âš ï¸ Allow w/ Constraints | âœ… |
| `auditor` | âœ… Allow | âœ… Allow | âš ï¸ Allow w/ Constraints | âœ… (no HIGH) |
| `data_analyst` | âœ… Allow | âŒ Deny | âŒ Deny | âŒ |

**Constraints for HIGH sensitivity access:**
- Must redact/mask narrative text
- Mandatory access logging in evidence pack
- Max rows limited (100 for compliance, 50 for auditor)
- Min group size â‰¥ 10 (k-anonymity)

## Metrics Catalog

| Metric | Data Product | Sensitivity |
|--------|-------------|-------------|
| `complaint_count` | dp_complaints | LOW |
| `net_income_sum` | dp_call_reports | MED |
| `net_income_avg` | dp_call_reports | MED |
| `deposits_sum` | dp_call_reports | LOW |
| `tier1_ratio_avg` | dp_call_reports | LOW |
| `npa_ratio` | dp_call_reports | MED |

## Example Queries

### Branch Manager
```
Show complaint counts by product and state for the last 12 months
â†’ âœ… Returns aggregated data with min_group_size=10 enforced
```

### Risk Officer
```
What is the average net income by bank by quarter?
â†’ âœ… Returns quarterly financial data
```

### Compliance Officer
```
Show me complaint narratives for investigations
â†’ âš ï¸ ALLOW_WITH_CONSTRAINTS: narratives are redacted, access logged
```

### Branch Manager (denied)
```
Show me complaint narratives
â†’ âŒ DENIED: High sensitivity data not available for this role
```

## Evidence Pack

Every query produces a JSON evidence pack containing:

- `request_id` - Unique identifier
- `timestamp` - ISO 8601 timestamp
- `user_attributes` - Role, region, purpose
- `policy_decision` - ALLOW/DENY/ALLOW_WITH_CONSTRAINTS + reason
- `metrics` - Metric IDs and versions used
- `data_products` - Products used with versions
- `data_quality` - Freshness and test status
- `sql` - Final SQL, canonical SQL, SHA256 hash
- `results` - Row count, suppression count
- `lineage` - OpenLineage event ID
- `export` - Export artifact path (if generated)

## Makefile Targets

```bash
make demo              # Full demo: generate data, ingest, promote, run UI
make build-data        # Generate synthetic data (small mode)
make build-data-full   # Generate full 1M row dataset
make ingest            # Run full ingestion pipeline
make validate-schema   # Validate CSV schemas
make seed              # Seed DuckDB
make ge-check          # Run quality checks
make promote           # Promote data products
make promote-fail-dbt  # Test: promote with dbt failure
make promote-fail-ge   # Test: promote with GE failure
make run-ui            # Run Streamlit UI
make test              # Run pytest suite
make docker-up         # Docker compose up
make docker-down       # Docker compose down
make clean             # Clean generated files
```

## Project Structure

```
â”œâ”€â”€ docker-compose.yml          # Docker services (app, OPA, Marquez)
â”œâ”€â”€ Dockerfile                  # App container
â”œâ”€â”€ Makefile                    # Build targets
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ data/                       # Synthetic data (CSV) + DuckDB
â”œâ”€â”€ catalog/                    # Metrics & data product definitions
â”‚   â”œâ”€â”€ metrics.yml
â”‚   â”œâ”€â”€ data_products.yml
â”‚   â”œâ”€â”€ schemas/                # JSON schemas for validation
â”‚   â””â”€â”€ loader.py               # Python catalog loader
â”œâ”€â”€ policies/                   # OPA Rego policies
â”‚   â”œâ”€â”€ banking.rego
â”‚   â””â”€â”€ example_inputs/         # Example policy inputs
â”œâ”€â”€ dbt/                        # dbt project
â”‚   â”œâ”€â”€ models/staging/         # stg_complaints, stg_call_reports
â”‚   â”œâ”€â”€ models/gold/            # dp_complaints, dp_call_reports
â”‚   â””â”€â”€ tests/
â”œâ”€â”€ agent/                      # Analytics agent
â”‚   â”œâ”€â”€ graph.py                # LangGraph-style orchestration
â”‚   â”œâ”€â”€ sql_validator.py        # SQL validation + hashing
â”‚   â”œâ”€â”€ policy_client.py        # OPA client + local fallback
â”‚   â”œâ”€â”€ metadata_search.py      # Metric/data product search
â”‚   â”œâ”€â”€ evidence.py             # Evidence pack creation
â”‚   â”œâ”€â”€ quality.py              # Quality status checks
â”‚   â”œâ”€â”€ lineage.py              # OpenLineage events
â”‚   â””â”€â”€ query_executor.py       # DuckDB execution
â”œâ”€â”€ app/                        # Streamlit UI
â”‚   â””â”€â”€ streamlit_app.py
â”œâ”€â”€ scripts/                    # Utility scripts
â”‚   â”œâ”€â”€ generate_synth_data.py  # Synthetic data generator
â”‚   â”œâ”€â”€ seed_duckdb.py          # Load CSV â†’ DuckDB
â”‚   â”œâ”€â”€ validate_schema.py      # Schema validation
â”‚   â”œâ”€â”€ promote.py              # Data product promotion
â”‚   â”œâ”€â”€ ingest.py               # Full ingestion pipeline
â”‚   â””â”€â”€ run_lineage.py          # View lineage events
â”œâ”€â”€ great_expectations/         # Quality checks
â”‚   â””â”€â”€ run_checks.py
â”œâ”€â”€ tests/                      # Pytest test suite
â”‚   â””â”€â”€ test_banking_analytics.py
â””â”€â”€ artifacts/                  # Generated outputs
    â”œâ”€â”€ evidence_packs/
    â”œâ”€â”€ exports/
    â””â”€â”€ lineage_events/
```

## Testing

```bash
python -m pytest tests/ -v
```

42 tests covering:
- Policy deny narratives for unauthorized roles
- SQL validator blocks raw/staging tables
- Evidence pack required fields and SQL hash stability
- Promote blocking on failed quality checks
- Catalog loading and metadata search
- Export permission checks

## Security Rules

- **No PII output** - No raw IDs beyond synthetic complaint_id/bank_id
- **Narratives are HIGH sensitivity** - Default deny
- **Policy-first** - POLICY_EVAL runs before SQL generation
- **Safe defaults** - Ambiguous requests use most aggregated interpretation
- **Min group size** - Global k-anonymity enforcement (default: 10)
- **SQL safety** - Only dp_* tables allowed; no PRAGMA, ATTACH, file reads, DDL/DML
- **Audit trail** - Every response includes evidence pack
- **Quality gating** - Failed quality checks prevent querying

## License

This is a demo/educational system. Not for production use with real financial data.